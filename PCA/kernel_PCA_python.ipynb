{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397784ed",
   "metadata": {},
   "source": [
    "# Kernel PCA in python\n",
    "\n",
    "Run on data from `./Data/all_in_one.csv`. It's a file which combined files `train.csv` and `unique_m.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70bb5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694119c",
   "metadata": {},
   "source": [
    "### Downloading, spliting and standartisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a92d003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "data = pd.read_csv('./Data/all_in_one.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08f92c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \n",
    "train, test = train_test_split(data, test_size = 0.25, random_state = 0)\n",
    "\n",
    "X_train = test.drop('critical_temp', axis=1)\n",
    "X_test = train.drop('critical_temp', axis=1)\n",
    "\n",
    "y_train = train[['critical_temp']]\n",
    "y_test = test[['critical_temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ede20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standartisation\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7417bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA with all components\n",
    "\n",
    "kpca = KernelPCA(n_components = 158, kernel = 'rbf', n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = kpca.fit_transform(X_train)\n",
    "X_test = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d702abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression\n",
    "l_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85d69700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "l_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = l_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dac9afd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.937</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.936</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3505.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:47:14</td>     <th>  Log-Likelihood:    </th> <td> -39063.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15947</td>      <th>  AIC:               </th> <td>7.826e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15879</td>      <th>  BIC:               </th> <td>7.878e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    67</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   34.3753</td> <td>    0.022</td> <td> 1545.537</td> <td> 0.000</td> <td>   34.332</td> <td>   34.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   75.7050</td> <td>    0.302</td> <td>  250.929</td> <td> 0.000</td> <td>   75.114</td> <td>   76.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   31.9811</td> <td>    0.400</td> <td>   79.889</td> <td> 0.000</td> <td>   31.196</td> <td>   32.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   56.0551</td> <td>    0.454</td> <td>  123.380</td> <td> 0.000</td> <td>   55.165</td> <td>   56.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    6.5553</td> <td>    0.464</td> <td>   14.118</td> <td> 0.000</td> <td>    5.645</td> <td>    7.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    3.9175</td> <td>    0.496</td> <td>    7.902</td> <td> 0.000</td> <td>    2.946</td> <td>    4.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   46.5324</td> <td>    0.518</td> <td>   89.858</td> <td> 0.000</td> <td>   45.517</td> <td>   47.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   66.4076</td> <td>    0.543</td> <td>  122.279</td> <td> 0.000</td> <td>   65.343</td> <td>   67.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -5.7262</td> <td>    0.548</td> <td>  -10.445</td> <td> 0.000</td> <td>   -6.801</td> <td>   -4.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  -12.8279</td> <td>    0.577</td> <td>  -22.240</td> <td> 0.000</td> <td>  -13.958</td> <td>  -11.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   57.4102</td> <td>    0.579</td> <td>   99.201</td> <td> 0.000</td> <td>   56.276</td> <td>   58.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   58.6056</td> <td>    0.598</td> <td>   97.970</td> <td> 0.000</td> <td>   57.433</td> <td>   59.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    8.8641</td> <td>    0.603</td> <td>   14.703</td> <td> 0.000</td> <td>    7.682</td> <td>   10.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>  -14.2751</td> <td>    0.614</td> <td>  -23.260</td> <td> 0.000</td> <td>  -15.478</td> <td>  -13.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   39.0135</td> <td>    0.621</td> <td>   62.806</td> <td> 0.000</td> <td>   37.796</td> <td>   40.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -1.9714</td> <td>    0.624</td> <td>   -3.158</td> <td> 0.002</td> <td>   -3.195</td> <td>   -0.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>  -36.0611</td> <td>    0.629</td> <td>  -57.318</td> <td> 0.000</td> <td>  -37.294</td> <td>  -34.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   42.8981</td> <td>    0.634</td> <td>   67.609</td> <td> 0.000</td> <td>   41.654</td> <td>   44.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    1.3371</td> <td>    0.639</td> <td>    2.093</td> <td> 0.036</td> <td>    0.085</td> <td>    2.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  -13.9652</td> <td>    0.651</td> <td>  -21.442</td> <td> 0.000</td> <td>  -15.242</td> <td>  -12.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -3.1581</td> <td>    0.653</td> <td>   -4.834</td> <td> 0.000</td> <td>   -4.439</td> <td>   -1.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    5.5987</td> <td>    0.662</td> <td>    8.464</td> <td> 0.000</td> <td>    4.302</td> <td>    6.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   59.5772</td> <td>    0.678</td> <td>   87.934</td> <td> 0.000</td> <td>   58.249</td> <td>   60.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>  -27.5755</td> <td>    0.686</td> <td>  -40.169</td> <td> 0.000</td> <td>  -28.921</td> <td>  -26.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   58.9172</td> <td>    0.687</td> <td>   85.773</td> <td> 0.000</td> <td>   57.571</td> <td>   60.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.0893</td> <td>    0.716</td> <td>    0.125</td> <td> 0.901</td> <td>   -1.315</td> <td>    1.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   72.2621</td> <td>    0.719</td> <td>  100.539</td> <td> 0.000</td> <td>   70.853</td> <td>   73.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   79.6701</td> <td>    0.725</td> <td>  109.940</td> <td> 0.000</td> <td>   78.250</td> <td>   81.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -6.6358</td> <td>    0.732</td> <td>   -9.066</td> <td> 0.000</td> <td>   -8.071</td> <td>   -5.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    4.5197</td> <td>    0.751</td> <td>    6.020</td> <td> 0.000</td> <td>    3.048</td> <td>    5.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>  -19.2776</td> <td>    0.754</td> <td>  -25.579</td> <td> 0.000</td> <td>  -20.755</td> <td>  -17.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>  -26.0777</td> <td>    0.756</td> <td>  -34.476</td> <td> 0.000</td> <td>  -27.560</td> <td>  -24.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>  -26.6076</td> <td>    0.759</td> <td>  -35.063</td> <td> 0.000</td> <td>  -28.095</td> <td>  -25.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>  -34.7747</td> <td>    0.760</td> <td>  -45.736</td> <td> 0.000</td> <td>  -36.265</td> <td>  -33.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   12.1868</td> <td>    0.763</td> <td>   15.971</td> <td> 0.000</td> <td>   10.691</td> <td>   13.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    5.7402</td> <td>    0.776</td> <td>    7.395</td> <td> 0.000</td> <td>    4.219</td> <td>    7.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>  -39.4733</td> <td>    0.789</td> <td>  -50.000</td> <td> 0.000</td> <td>  -41.021</td> <td>  -37.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   56.6065</td> <td>    0.791</td> <td>   71.605</td> <td> 0.000</td> <td>   55.057</td> <td>   58.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -9.0417</td> <td>    0.796</td> <td>  -11.359</td> <td> 0.000</td> <td>  -10.602</td> <td>   -7.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   62.2218</td> <td>    0.802</td> <td>   77.616</td> <td> 0.000</td> <td>   60.650</td> <td>   63.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -8.6080</td> <td>    0.809</td> <td>  -10.634</td> <td> 0.000</td> <td>  -10.195</td> <td>   -7.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    4.7064</td> <td>    0.815</td> <td>    5.775</td> <td> 0.000</td> <td>    3.109</td> <td>    6.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>  -23.5601</td> <td>    0.816</td> <td>  -28.869</td> <td> 0.000</td> <td>  -25.160</td> <td>  -21.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>  -30.6252</td> <td>    0.825</td> <td>  -37.143</td> <td> 0.000</td> <td>  -32.241</td> <td>  -29.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   48.5757</td> <td>    0.827</td> <td>   58.712</td> <td> 0.000</td> <td>   46.954</td> <td>   50.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   39.5163</td> <td>    0.828</td> <td>   47.748</td> <td> 0.000</td> <td>   37.894</td> <td>   41.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -9.5560</td> <td>    0.829</td> <td>  -11.525</td> <td> 0.000</td> <td>  -11.181</td> <td>   -7.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    4.0031</td> <td>    0.832</td> <td>    4.810</td> <td> 0.000</td> <td>    2.372</td> <td>    5.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   25.4767</td> <td>    0.837</td> <td>   30.456</td> <td> 0.000</td> <td>   23.837</td> <td>   27.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    3.6702</td> <td>    0.840</td> <td>    4.369</td> <td> 0.000</td> <td>    2.024</td> <td>    5.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    9.0227</td> <td>    0.848</td> <td>   10.639</td> <td> 0.000</td> <td>    7.360</td> <td>   10.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>  -15.3271</td> <td>    0.849</td> <td>  -18.061</td> <td> 0.000</td> <td>  -16.991</td> <td>  -13.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>  -17.7248</td> <td>    0.850</td> <td>  -20.854</td> <td> 0.000</td> <td>  -19.391</td> <td>  -16.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>  -15.9892</td> <td>    0.853</td> <td>  -18.754</td> <td> 0.000</td> <td>  -17.660</td> <td>  -14.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>  -27.2075</td> <td>    0.855</td> <td>  -31.824</td> <td> 0.000</td> <td>  -28.883</td> <td>  -25.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    4.1816</td> <td>    0.858</td> <td>    4.876</td> <td> 0.000</td> <td>    2.501</td> <td>    5.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>  103.3673</td> <td>    0.860</td> <td>  120.163</td> <td> 0.000</td> <td>  101.681</td> <td>  105.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>   67.8005</td> <td>    0.875</td> <td>   77.493</td> <td> 0.000</td> <td>   66.086</td> <td>   69.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   22.9503</td> <td>    0.879</td> <td>   26.098</td> <td> 0.000</td> <td>   21.227</td> <td>   24.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   -7.5764</td> <td>    0.886</td> <td>   -8.556</td> <td> 0.000</td> <td>   -9.312</td> <td>   -5.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>    3.3288</td> <td>    0.888</td> <td>    3.749</td> <td> 0.000</td> <td>    1.588</td> <td>    5.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>  -27.3217</td> <td>    0.888</td> <td>  -30.756</td> <td> 0.000</td> <td>  -29.063</td> <td>  -25.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>    6.4795</td> <td>    0.890</td> <td>    7.282</td> <td> 0.000</td> <td>    4.735</td> <td>    8.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>  -13.1968</td> <td>    0.891</td> <td>  -14.815</td> <td> 0.000</td> <td>  -14.943</td> <td>  -11.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>   15.0270</td> <td>    0.894</td> <td>   16.817</td> <td> 0.000</td> <td>   13.276</td> <td>   16.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>  -26.7772</td> <td>    0.898</td> <td>  -29.831</td> <td> 0.000</td> <td>  -28.537</td> <td>  -25.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>    3.3907</td> <td>    0.898</td> <td>    3.774</td> <td> 0.000</td> <td>    1.630</td> <td>    5.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>  -19.8721</td> <td>    0.903</td> <td>  -21.996</td> <td> 0.000</td> <td>  -21.643</td> <td>  -18.101</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4951.147</td> <th>  Durbin-Watson:     </th>  <td>   1.991</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>893421.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.213</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39.666</td>  <th>  Cond. No.          </th>  <td>    40.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.937\n",
       "Model:                            OLS   Adj. R-squared:                  0.936\n",
       "Method:                 Least Squares   F-statistic:                     3505.\n",
       "Date:                Wed, 08 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        21:47:14   Log-Likelihood:                -39063.\n",
       "No. Observations:               15947   AIC:                         7.826e+04\n",
       "Df Residuals:                   15879   BIC:                         7.878e+04\n",
       "Df Model:                          67                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         34.3753      0.022   1545.537      0.000      34.332      34.419\n",
       "x1            75.7050      0.302    250.929      0.000      75.114      76.296\n",
       "x2            31.9811      0.400     79.889      0.000      31.196      32.766\n",
       "x3            56.0551      0.454    123.380      0.000      55.165      56.946\n",
       "x4             6.5553      0.464     14.118      0.000       5.645       7.465\n",
       "x5             3.9175      0.496      7.902      0.000       2.946       4.889\n",
       "x6            46.5324      0.518     89.858      0.000      45.517      47.547\n",
       "x7            66.4076      0.543    122.279      0.000      65.343      67.472\n",
       "x8            -5.7262      0.548    -10.445      0.000      -6.801      -4.652\n",
       "x9           -12.8279      0.577    -22.240      0.000     -13.958     -11.697\n",
       "x10           57.4102      0.579     99.201      0.000      56.276      58.545\n",
       "x11           58.6056      0.598     97.970      0.000      57.433      59.778\n",
       "x12            8.8641      0.603     14.703      0.000       7.682      10.046\n",
       "x13          -14.2751      0.614    -23.260      0.000     -15.478     -13.072\n",
       "x14           39.0135      0.621     62.806      0.000      37.796      40.231\n",
       "x15           -1.9714      0.624     -3.158      0.002      -3.195      -0.748\n",
       "x16          -36.0611      0.629    -57.318      0.000     -37.294     -34.828\n",
       "x17           42.8981      0.634     67.609      0.000      41.654      44.142\n",
       "x18            1.3371      0.639      2.093      0.036       0.085       2.589\n",
       "x19          -13.9652      0.651    -21.442      0.000     -15.242     -12.689\n",
       "x20           -3.1581      0.653     -4.834      0.000      -4.439      -1.878\n",
       "x21            5.5987      0.662      8.464      0.000       4.302       6.895\n",
       "x22           59.5772      0.678     87.934      0.000      58.249      60.905\n",
       "x23          -27.5755      0.686    -40.169      0.000     -28.921     -26.230\n",
       "x24           58.9172      0.687     85.773      0.000      57.571      60.264\n",
       "x25            0.0893      0.716      0.125      0.901      -1.315       1.493\n",
       "x26           72.2621      0.719    100.539      0.000      70.853      73.671\n",
       "x27           79.6701      0.725    109.940      0.000      78.250      81.091\n",
       "x28           -6.6358      0.732     -9.066      0.000      -8.071      -5.201\n",
       "x29            4.5197      0.751      6.020      0.000       3.048       5.991\n",
       "x30          -19.2776      0.754    -25.579      0.000     -20.755     -17.800\n",
       "x31          -26.0777      0.756    -34.476      0.000     -27.560     -24.595\n",
       "x32          -26.6076      0.759    -35.063      0.000     -28.095     -25.120\n",
       "x33          -34.7747      0.760    -45.736      0.000     -36.265     -33.284\n",
       "x34           12.1868      0.763     15.971      0.000      10.691      13.682\n",
       "x35            5.7402      0.776      7.395      0.000       4.219       7.262\n",
       "x36          -39.4733      0.789    -50.000      0.000     -41.021     -37.926\n",
       "x37           56.6065      0.791     71.605      0.000      55.057      58.156\n",
       "x38           -9.0417      0.796    -11.359      0.000     -10.602      -7.481\n",
       "x39           62.2218      0.802     77.616      0.000      60.650      63.793\n",
       "x40           -8.6080      0.809    -10.634      0.000     -10.195      -7.021\n",
       "x41            4.7064      0.815      5.775      0.000       3.109       6.304\n",
       "x42          -23.5601      0.816    -28.869      0.000     -25.160     -21.960\n",
       "x43          -30.6252      0.825    -37.143      0.000     -32.241     -29.009\n",
       "x44           48.5757      0.827     58.712      0.000      46.954      50.197\n",
       "x45           39.5163      0.828     47.748      0.000      37.894      41.139\n",
       "x46           -9.5560      0.829    -11.525      0.000     -11.181      -7.931\n",
       "x47            4.0031      0.832      4.810      0.000       2.372       5.634\n",
       "x48           25.4767      0.837     30.456      0.000      23.837      27.116\n",
       "x49            3.6702      0.840      4.369      0.000       2.024       5.317\n",
       "x50            9.0227      0.848     10.639      0.000       7.360      10.685\n",
       "x51          -15.3271      0.849    -18.061      0.000     -16.991     -13.664\n",
       "x52          -17.7248      0.850    -20.854      0.000     -19.391     -16.059\n",
       "x53          -15.9892      0.853    -18.754      0.000     -17.660     -14.318\n",
       "x54          -27.2075      0.855    -31.824      0.000     -28.883     -25.532\n",
       "x55            4.1816      0.858      4.876      0.000       2.501       5.862\n",
       "x56          103.3673      0.860    120.163      0.000     101.681     105.053\n",
       "x57           67.8005      0.875     77.493      0.000      66.086      69.515\n",
       "x58           22.9503      0.879     26.098      0.000      21.227      24.674\n",
       "x59           -7.5764      0.886     -8.556      0.000      -9.312      -5.841\n",
       "x60            3.3288      0.888      3.749      0.000       1.588       5.069\n",
       "x61          -27.3217      0.888    -30.756      0.000     -29.063     -25.580\n",
       "x62            6.4795      0.890      7.282      0.000       4.735       8.224\n",
       "x63          -13.1968      0.891    -14.815      0.000     -14.943     -11.451\n",
       "x64           15.0270      0.894     16.817      0.000      13.276      16.778\n",
       "x65          -26.7772      0.898    -29.831      0.000     -28.537     -25.018\n",
       "x66            3.3907      0.898      3.774      0.000       1.630       5.152\n",
       "x67          -19.8721      0.903    -21.996      0.000     -21.643     -18.101\n",
       "==============================================================================\n",
       "Omnibus:                     4951.147   Durbin-Watson:                   1.991\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           893421.044\n",
       "Skew:                           0.213   Prob(JB):                         0.00\n",
       "Kurtosis:                      39.666   Cond. No.                         40.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y_train = l_model.predict(X_train)\n",
    "\n",
    "X = sm.add_constant(X_train.ravel())\n",
    "results = sm.OLS(y_train, x).fit()\n",
    "results.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf4590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
